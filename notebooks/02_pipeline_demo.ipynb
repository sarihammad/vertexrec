{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# VertexRec Pipeline Demo\n",
        "\n",
        "This notebook demonstrates the VertexRec ML pipeline execution, including data validation, feature engineering, model training, and evaluation.\n",
        "\n",
        "## Table of Contents\n",
        "1. [Pipeline Setup](#pipeline-setup)\n",
        "2. [Data Validation](#data-validation)\n",
        "3. [Feature Engineering](#feature-engineering)\n",
        "4. [Model Training](#model-training)\n",
        "5. [Model Evaluation](#model-evaluation)\n",
        "6. [Pipeline Results](#pipeline-results)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "import sys\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Add pipeline modules to path\n",
        "sys.path.append('../pipelines')\n",
        "sys.path.append('../scripts')\n",
        "\n",
        "print(\"Libraries imported successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Pipeline Setup {#pipeline-setup}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set up pipeline configuration\n",
        "PROJECT_ID = \"your-gcp-project-id\"  # Replace with your project ID\n",
        "REGION = \"us-central1\"\n",
        "BUCKET_NAME = f\"vertexrec-data-{PROJECT_ID}\"\n",
        "\n",
        "# Data paths\n",
        "DATA_DIR = Path(\"../data\")\n",
        "USERS_DATA = DATA_DIR / \"users.csv\"\n",
        "ITEMS_DATA = DATA_DIR / \"items.csv\"\n",
        "INTERACTIONS_DATA = DATA_DIR / \"interactions.csv\"\n",
        "\n",
        "# Output directories\n",
        "OUTPUT_DIR = Path(\"../output\")\n",
        "OUTPUT_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "print(\"Pipeline configuration set up successfully!\")\n",
        "print(f\"Project ID: {PROJECT_ID}\")\n",
        "print(f\"Region: {REGION}\")\n",
        "print(f\"Bucket: {BUCKET_NAME}\")\n",
        "print(f\"Data directory: {DATA_DIR}\")\n",
        "print(f\"Output directory: {OUTPUT_DIR}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Data Validation {#data-validation}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run data validation\n",
        "from data_validation.validate_data import DataValidator\n",
        "\n",
        "# Initialize validator\n",
        "validator = DataValidator(str(OUTPUT_DIR / \"validation\"))\n",
        "\n",
        "# Validate each dataset\n",
        "print(\"Validating users data...\")\n",
        "users_valid, users_anomalies = validator.validate_users_data(str(USERS_DATA))\n",
        "\n",
        "print(\"Validating items data...\")\n",
        "items_valid, items_anomalies = validator.validate_items_data(str(ITEMS_DATA))\n",
        "\n",
        "print(\"Validating interactions data...\")\n",
        "interactions_valid, interactions_anomalies = validator.validate_interactions_data(str(INTERACTIONS_DATA))\n",
        "\n",
        "# Print validation results\n",
        "print(f\"\\n=== VALIDATION RESULTS ===\")\n",
        "print(f\"Users data: {'‚úì Valid' if users_valid else '‚úó Invalid'}\")\n",
        "print(f\"Items data: {'‚úì Valid' if items_valid else '‚úó Invalid'}\")\n",
        "print(f\"Interactions data: {'‚úì Valid' if interactions_valid else '‚úó Invalid'}\")\n",
        "\n",
        "if not all([users_valid, items_valid, interactions_valid]):\n",
        "    print(\"\\nValidation failed! Check anomaly files for details.\")\n",
        "else:\n",
        "    print(\"\\nAll data validation passed successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Feature Engineering {#feature-engineering}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run feature engineering\n",
        "from feature_engineering.feature_engineering import FeatureEngineer\n",
        "\n",
        "# Initialize feature engineer\n",
        "feature_engineer = FeatureEngineer(str(OUTPUT_DIR / \"features\"))\n",
        "\n",
        "# Load data\n",
        "print(\"Loading data for feature engineering...\")\n",
        "users_df, items_df, interactions_df = feature_engineer.load_data(\n",
        "    str(USERS_DATA), str(ITEMS_DATA), str(INTERACTIONS_DATA)\n",
        ")\n",
        "\n",
        "# Engineer features\n",
        "print(\"Engineering user features...\")\n",
        "user_features = feature_engineer.engineer_user_features(users_df, interactions_df)\n",
        "\n",
        "print(\"Engineering item features...\")\n",
        "item_features = feature_engineer.engineer_item_features(items_df, interactions_df)\n",
        "\n",
        "print(\"Engineering interaction features...\")\n",
        "interaction_features = feature_engineer.engineer_interaction_features(\n",
        "    interactions_df, users_df, items_df\n",
        ")\n",
        "\n",
        "# Save features\n",
        "print(\"Saving engineered features...\")\n",
        "feature_engineer.save_features(user_features, item_features, interaction_features)\n",
        "\n",
        "# Display feature summary\n",
        "summary = feature_engineer.create_feature_summary(user_features, item_features, interaction_features)\n",
        "\n",
        "print(f\"\\n=== FEATURE ENGINEERING RESULTS ===\")\n",
        "print(f\"User features: {summary['user_features']['count']} features\")\n",
        "print(f\"Item features: {summary['item_features']['count']} features\")\n",
        "print(f\"Interaction features: {summary['interaction_features']['count']} features\")\n",
        "\n",
        "print(\"\\nSample user features:\")\n",
        "display(user_features.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Model Training {#model-training}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train TF Recommenders model\n",
        "from training.tf_recommenders_trainer import TFRecommendersTrainer\n",
        "\n",
        "print(\"Training TF Recommenders model...\")\n",
        "tf_trainer = TFRecommendersTrainer(\n",
        "    output_dir=str(OUTPUT_DIR / \"models\" / \"tf_recommenders\"),\n",
        "    embedding_dim=32,  # Smaller for demo\n",
        "    learning_rate=0.01\n",
        ")\n",
        "\n",
        "# Train model\n",
        "tf_model = tf_trainer.train(\n",
        "    interactions_path=str(INTERACTIONS_DATA),\n",
        "    users_path=str(USERS_DATA),\n",
        "    items_path=str(ITEMS_DATA),\n",
        "    epochs=5,  # Fewer epochs for demo\n",
        "    validation_split=0.2\n",
        ")\n",
        "\n",
        "print(\"TF Recommenders model training completed!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train XGBoost model\n",
        "from training.xgboost_trainer import XGBoostRankingTrainer\n",
        "\n",
        "print(\"Training XGBoost model...\")\n",
        "xgb_trainer = XGBoostRankingTrainer(\n",
        "    output_dir=str(OUTPUT_DIR / \"models\" / \"xgboost\")\n",
        ")\n",
        "\n",
        "# Model parameters for demo\n",
        "model_params = {\n",
        "    'n_estimators': 50,  # Fewer trees for demo\n",
        "    'max_depth': 4,\n",
        "    'learning_rate': 0.1\n",
        "}\n",
        "\n",
        "# Train model\n",
        "xgb_model = xgb_trainer.train(\n",
        "    interactions_path=str(INTERACTIONS_DATA),\n",
        "    users_path=str(USERS_DATA),\n",
        "    items_path=str(ITEMS_DATA),\n",
        "    validation_split=0.2,\n",
        "    model_params=model_params\n",
        ")\n",
        "\n",
        "print(\"XGBoost model training completed!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Model Evaluation {#model-evaluation}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate models\n",
        "from evaluation.evaluation_metrics import RecommendationEvaluator\n",
        "\n",
        "print(\"Evaluating models...\")\n",
        "evaluator = RecommendationEvaluator(str(OUTPUT_DIR / \"evaluation\"))\n",
        "\n",
        "# Load data\n",
        "interactions_df, users_df, items_df = evaluator.load_data(\n",
        "    str(INTERACTIONS_DATA), str(USERS_DATA), str(ITEMS_DATA)\n",
        ")\n",
        "\n",
        "# Split data\n",
        "train_df, test_df = evaluator.split_data(interactions_df)\n",
        "\n",
        "# Create dummy recommendations for demo (in real pipeline, use trained models)\n",
        "print(\"Generating recommendations for evaluation...\")\n",
        "recommendations = {}\n",
        "for user_id in test_df['user_id'].unique()[:100]:  # Limit for demo\n",
        "    recommendations[user_id] = test_df[\n",
        "        test_df['user_id'] != user_id\n",
        "    ]['item_id'].unique()[:10].tolist()\n",
        "\n",
        "# Evaluate recommendations\n",
        "results = evaluator.evaluate_recommendations(\n",
        "    recommendations, test_df, items_df, len(items_df), k_values=[5, 10]\n",
        ")\n",
        "\n",
        "# Save results\n",
        "evaluator.save_results(results)\n",
        "\n",
        "# Generate report\n",
        "report = evaluator.generate_report(results)\n",
        "print(report)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Pipeline Results {#pipeline-results}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display pipeline results summary\n",
        "print(\"=== VERTEXREC PIPELINE DEMO COMPLETED ===\")\n",
        "print(\"\\nPipeline Components:\")\n",
        "print(\"‚úì Data Validation - All datasets validated successfully\")\n",
        "print(\"‚úì Feature Engineering - User, item, and interaction features created\")\n",
        "print(\"‚úì Model Training - TF Recommenders and XGBoost models trained\")\n",
        "print(\"‚úì Model Evaluation - Comprehensive evaluation metrics computed\")\n",
        "\n",
        "print(f\"\\nOutput Files Generated:\")\n",
        "print(f\"üìÅ {OUTPUT_DIR / 'validation'} - Data validation results\")\n",
        "print(f\"üìÅ {OUTPUT_DIR / 'features'} - Engineered features\")\n",
        "print(f\"üìÅ {OUTPUT_DIR / 'models'} - Trained models\")\n",
        "print(f\"üìÅ {OUTPUT_DIR / 'evaluation'} - Evaluation results\")\n",
        "\n",
        "print(f\"\\nKey Metrics:\")\n",
        "print(f\"üìä Recall@10: {results.get('recall@10', 'N/A'):.4f}\")\n",
        "print(f\"üìä NDCG@10: {results.get('ndcg@10', 'N/A'):.4f}\")\n",
        "print(f\"üìä MRR: {results.get('mrr', 'N/A'):.4f}\")\n",
        "print(f\"üìä Coverage: {results.get('coverage', 'N/A'):.4f}\")\n",
        "\n",
        "print(f\"\\nNext Steps:\")\n",
        "print(\"1. Deploy models to Vertex AI Endpoints\")\n",
        "print(\"2. Set up Cloud Run API service\")\n",
        "print(\"3. Configure monitoring and alerting\")\n",
        "print(\"4. Implement CI/CD pipeline\")\n",
        "print(\"5. Deploy to production environment\")\n",
        "\n",
        "print(f\"\\nüéâ Pipeline demo completed successfully!\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
